{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aicuai/Book-SD-MasterGuide/blob/main/AICU_ConfyUI_FLUX_1_on_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "# ComfyUIのインストール https://j.aicu.ai/Comfy\n",
        "\n",
        "この Google Colab向け notebook は ComfyUIを初心者向けに簡単に起動できるように解説・設定しています。\n",
        "\n",
        "原作は [ComfyUI-Manager](https://github.com/ltdrdata/ComfyUI-Manager) による [こちら](https://github.com/ltdrdata/ComfyUI-Manager/blob/main/notebooks/comfyui_colab_with_manager.ipynb)\n",
        "\n",
        "\n",
        "AICU mediaによる解説記事は[ここ](https://note.com/aicu/n/n876fab5a0736)から読めます\n",
        "\n",
        "■ ここからはじめる「ComfyUIマスターガイド」\n",
        "https://note.com/aicu/n/n876fab5a0736\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bbbbbbbbbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c767db9-541a-4029-b833-d097c980fc17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "/\n",
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/ComfyUI\n",
            "-= Updating ComfyUI =-\n",
            "Already up to date.\n",
            "-= Install dependencies =-\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting torchsde\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from torchsde) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from torchsde) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from torchsde) (2.3.1+cu121)\n",
            "Collecting trampoline>=0.1.2 (from torchsde)\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->torchsde) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->torchsde) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->torchsde) (1.3.0)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: trampoline, torchsde\n",
            "Successfully installed torchsde-0.2.6 trampoline-0.1.2\n",
            "/content/drive/MyDrive/ComfyUI/custom_nodes\n",
            "/content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "Already up to date.\n",
            "/content/drive/MyDrive/ComfyUI\n",
            "-= Install custom nodes dependencies =-\n",
            "Collecting GitPython\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, GitPython\n",
            "Successfully installed GitPython-3.1.43 gitdb-4.0.11 smmap-5.0.1\n",
            "\n",
            "\u001b[1;33mWARN: The `COMFYUI_PATH` environment variable is not set. Assuming \u001b[0m\n",
            "\u001b[1;33m`custom_nodes/ComfyUI-Manager/..\u001b[0m\u001b[1;33m/../\u001b[0m\u001b[1;33m` as the ComfyUI path.\u001b[0m\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Restoring \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m/\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m: \u001b[35m/content/drive/MyDrive/ComfyUI/custom_nodes/\u001b[0m\u001b[95m__pycache__\u001b[0m\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Restoring \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m/\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m: \u001b[35m/content/drive/MyDrive/ComfyUI/custom_nodes/\u001b[0m\u001b[95mComfyUI-Manager\u001b[0m\n",
            "...\n",
            "Collecting PyGithub\n",
            "  Downloading PyGithub-\u001b[1;36m2.3\u001b[0m.\u001b[1;36m0\u001b[0m-py3-none-any.whl.metadata \u001b[1m(\u001b[0m\u001b[1;36m3.8\u001b[0m kB\u001b[1m)\u001b[0m\n",
            "Collecting pynacl>=\u001b[1;36m1.4\u001b[0m.\u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mfrom PyGithub\u001b[1m)\u001b[0m\n",
            "  Downloading \n",
            "PyNaCl-\u001b[1;36m1.5\u001b[0m.\u001b[1;36m0\u001b[0m-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata\n",
            "\u001b[1m(\u001b[0m\u001b[1;36m8.6\u001b[0m kB\u001b[1m)\u001b[0m\n",
            "....Collecting Deprecated \u001b[1m(\u001b[0mfrom PyGithub\u001b[1m)\u001b[0m\n",
            "  Downloading Deprecated-\u001b[1;36m1.2\u001b[0m.\u001b[1;36m14\u001b[0m-py2.py3-none-any.whl.metadata \u001b[1m(\u001b[0m\u001b[1;36m5.4\u001b[0m kB\u001b[1m)\u001b[0m\n",
            ".......Downloading PyGithub-\u001b[1;36m2.3\u001b[0m.\u001b[1;36m0\u001b[0m-py3-none-any.whl \u001b[1m(\u001b[0m\u001b[1;36m354\u001b[0m kB\u001b[1m)\u001b[0m\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[1;36m354.4\u001b[0m/\u001b[1;36m354.4\u001b[0m kB \u001b[1;36m27.6\u001b[0m MB/s eta \u001b[1;92m0:00:00\u001b[0m\n",
            "Downloading \n",
            "PyNaCl-\u001b[1;36m1.5\u001b[0m.\u001b[1;36m0\u001b[0m-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl \u001b[1m(\u001b[0m\u001b[1;36m856\u001b[0m kB\u001b[1m)\u001b[0m\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[1;36m856.7\u001b[0m/\u001b[1;36m856.7\u001b[0m kB \u001b[1;36m52.1\u001b[0m MB/s eta \u001b[1;92m0:00:00\u001b[0m\n",
            "Downloading Deprecated-\u001b[1;36m1.2\u001b[0m.\u001b[1;36m14\u001b[0m-py2.py3-none-any.whl \u001b[1m(\u001b[0m\u001b[1;36m9.6\u001b[0m kB\u001b[1m)\u001b[0m\n",
            "Installing collected packages: Deprecated, pynacl, PyGithub\n",
            "Successfully installed Deprecated-\u001b[1;36m1.2\u001b[0m.\u001b[1;36m14\u001b[0m PyGithub-\u001b[1;36m2.3\u001b[0m.\u001b[1;36m0\u001b[0m pynacl-\u001b[1;36m1.5\u001b[0m.\u001b[1;36m0\u001b[0m\n",
            "\n",
            "Collecting matrix-\u001b[33mclient\u001b[0m==\u001b[1;36m0.4\u001b[0m.\u001b[1;36m0\u001b[0m\n",
            "  Downloading matrix_client-\u001b[1;36m0.4\u001b[0m.\u001b[1;36m0\u001b[0m-py2.py3-none-any.whl.metadata \u001b[1m(\u001b[0m\u001b[1;36m5.0\u001b[0m kB\u001b[1m)\u001b[0m\n",
            ".Collecting urllib3~=\u001b[1;36m1.21\u001b[0m \u001b[1m(\u001b[0mfrom matrix-\u001b[33mclient\u001b[0m==\u001b[1;36m0.4\u001b[0m.\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
            "  Downloading urllib3-\u001b[1;36m1.26\u001b[0m.\u001b[1;36m19\u001b[0m-py2.py3-none-any.whl.metadata \u001b[1m(\u001b[0m\u001b[1;36m49\u001b[0m kB\u001b[1m)\u001b[0m\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[1;36m49.3\u001b[0m/\u001b[1;36m49.3\u001b[0m kB \u001b[1;36m3.9\u001b[0m MB/s eta \u001b[1;92m0:00:00\u001b[0m\n",
            "...Downloading matrix_client-\u001b[1;36m0.4\u001b[0m.\u001b[1;36m0\u001b[0m-py2.py3-none-any.whl \u001b[1m(\u001b[0m\u001b[1;36m43\u001b[0m kB\u001b[1m)\u001b[0m\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[1;36m43.5\u001b[0m/\u001b[1;36m43.5\u001b[0m kB \u001b[1;36m3.8\u001b[0m MB/s eta \u001b[1;92m0:00:00\u001b[0m\n",
            "Downloading urllib3-\u001b[1;36m1.26\u001b[0m.\u001b[1;36m19\u001b[0m-py2.py3-none-any.whl \u001b[1m(\u001b[0m\u001b[1;36m143\u001b[0m kB\u001b[1m)\u001b[0m\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[1;36m143.9\u001b[0m/\u001b[1;36m143.9\u001b[0m kB \u001b[1;36m14.5\u001b[0m MB/s eta \u001b[1;92m0:00:00\u001b[0m\n",
            "Installing collected packages: urllib3, matrix-client\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 \u001b[1;36m2.0\u001b[0m.\u001b[1;36m7\u001b[0m\n",
            "    Uninstalling urllib3-\u001b[1;36m2.0\u001b[0m.\u001b[1;36m7\u001b[0m:\n",
            "      Successfully uninstalled urllib3-\u001b[1;36m2.0\u001b[0m.\u001b[1;36m7\u001b[0m\n",
            "Successfully installed matrix-client-\u001b[1;36m0.4\u001b[0m.\u001b[1;36m0\u001b[0m urllib3-\u001b[1;36m1.26\u001b[0m.\u001b[1;36m19\u001b[0m\n",
            "\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "# #@title Environment Setup\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
        "USE_COMFYUI_MANAGER = True  #@param {type:\"boolean\"}\n",
        "INSTALL_CUSTOM_NODES_DEPENDENCIES = True  #@param {type:\"boolean\"}\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "OPTIONS['USE_COMFYUI_MANAGER'] = USE_COMFYUI_MANAGER\n",
        "OPTIONS['INSTALL_CUSTOM_NODES_DEPENDENCIES'] = INSTALL_CUSTOM_NODES_DEPENDENCIES\n",
        "\n",
        "current_dir = !pwd\n",
        "WORKSPACE = f\"{current_dir[0]}/ComfyUI\"\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "\n",
        "  # Correction of the issue of permissions being deleted on Google Drive.\n",
        "  ![ -f \".ci/nightly/update_windows/update_comfyui_and_python_dependencies.bat\" ] && chmod 755 .ci/nightly/update_windows/update_comfyui_and_python_dependencies.bat\n",
        "  ![ -f \".ci/nightly/windows_base_files/run_nvidia_gpu.bat\" ] && chmod 755 .ci/nightly/windows_base_files/run_nvidia_gpu.bat\n",
        "  ![ -f \".ci/update_windows/update_comfyui_and_python_dependencies.bat\" ] && chmod 755 .ci/update_windows/update_comfyui_and_python_dependencies.bat\n",
        "  ![ -f \".ci/update_windows_cu118/update_comfyui_and_python_dependencies.bat\" ] && chmod 755 .ci/update_windows_cu118/update_comfyui_and_python_dependencies.bat\n",
        "  ![ -f \".ci/update_windows/update.py\" ] && chmod 755 .ci/update_windows/update.py\n",
        "  ![ -f \".ci/update_windows/update_comfyui.bat\" ] && chmod 755 .ci/update_windows/update_comfyui.bat\n",
        "  ![ -f \".ci/update_windows/README_VERY_IMPORTANT.txt\" ] && chmod 755 .ci/update_windows/README_VERY_IMPORTANT.txt\n",
        "  ![ -f \".ci/update_windows/run_cpu.bat\" ] && chmod 755 .ci/update_windows/run_cpu.bat\n",
        "  ![ -f \".ci/update_windows/run_nvidia_gpu.bat\" ] && chmod 755 .ci/update_windows/run_nvidia_gpu.bat\n",
        "\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip3 install accelerate\n",
        "!pip3 install einops transformers>=4.25.1 safetensors>=0.3.0 aiohttp pyyaml Pillow scipy tqdm psutil\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip3 install torchsde\n",
        "!pip3 install kornia>=0.7.1 spandrel\n",
        "\n",
        "if OPTIONS['USE_COMFYUI_MANAGER']:\n",
        "  %cd custom_nodes\n",
        "\n",
        "  # Correction of the issue of permissions being deleted on Google Drive.\n",
        "  ![ -f \"ComfyUI-Manager/check.sh\" ] && chmod 755 ComfyUI-Manager/check.sh\n",
        "  ![ -f \"ComfyUI-Manager/scan.sh\" ] && chmod 755 ComfyUI-Manager/scan.sh\n",
        "  ![ -f \"ComfyUI-Manager/node_db/dev/scan.sh\" ] && chmod 755 ComfyUI-Manager/node_db/dev/scan.sh\n",
        "  ![ -f \"ComfyUI-Manager/scripts/install-comfyui-venv-linux.sh\" ] && chmod 755 ComfyUI-Manager/scripts/install-comfyui-venv-linux.sh\n",
        "  ![ -f \"ComfyUI-Manager/scripts/install-comfyui-venv-win.bat\" ] && chmod 755 ComfyUI-Manager/scripts/install-comfyui-venv-win.bat\n",
        "\n",
        "  ![ ! -d ComfyUI-Manager ] && echo -= Initial setup ComfyUI-Manager =- && git clone https://github.com/ltdrdata/ComfyUI-Manager\n",
        "  %cd ComfyUI-Manager\n",
        "  !git pull\n",
        "\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['INSTALL_CUSTOM_NODES_DEPENDENCIES']:\n",
        "  !echo -= Install custom nodes dependencies =-\n",
        "  !pip install GitPython\n",
        "  !python custom_nodes/ComfyUI-Manager/cm-cli.py restore-dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": [
        "### 各種モデルのダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dddddddddd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991461fb-79ad-4549-fc6c-b47ef8bd7246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-05 11:04:08--  https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\n",
            "Resolving huggingface.co (huggingface.co)... 18.67.181.126, 18.67.181.100, 18.67.181.36, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.67.181.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/6b/20/6b201da5f0f5c60524535ebb7deac2eef68605655d3bbacfee9cce0087f3b3f5/cc6cb27103417325ff94f52b7a5d2dde45a7515b25c255d8e396c90014281516?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27v1-5-pruned-emaonly.ckpt%3B+filename%3D%22v1-5-pruned-emaonly.ckpt%22%3B&Expires=1723114346&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMzExNDM0Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82Yi8yMC82YjIwMWRhNWYwZjVjNjA1MjQ1MzVlYmI3ZGVhYzJlZWY2ODYwNTY1NWQzYmJhY2ZlZTljY2UwMDg3ZjNiM2Y1L2NjNmNiMjcxMDM0MTczMjVmZjk0ZjUyYjdhNWQyZGRlNDVhNzUxNWIyNWMyNTVkOGUzOTZjOTAwMTQyODE1MTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=kKOwZt6%7EZTr8gBHBExVvyeDxt-mPhHeYA3-MhfsL0wc608Q0zJGfR3p--KeRUqfU0ZzPJSyAMBUWhyiGdoA4rYC0cUSOMJpUn0xUgw0GzM-JTewLgcE8NS-UMrPxCPJ3941ZEh849jaF--CLC4yHHW%7E-EGCz53nCflPu9U8Qx1pjfRgibQ7SA2BN24o62h%7EDpncBqsUr1%7EOlqsd56qjh79O7GRIGzUud4QkNQeUKDfiGQsHZad2KAV5-Atr4Q2iPUXwkLu2xwEauNoFhR5-VKlSCSQoDovi6UHb64VWiivZVZJkmLEMaJPz9fh6H8afyH3Xejy2wpiAY%7Ez%7E%7E0-FKvQ__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-08-05 11:04:08--  https://cdn-lfs.huggingface.co/repos/6b/20/6b201da5f0f5c60524535ebb7deac2eef68605655d3bbacfee9cce0087f3b3f5/cc6cb27103417325ff94f52b7a5d2dde45a7515b25c255d8e396c90014281516?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27v1-5-pruned-emaonly.ckpt%3B+filename%3D%22v1-5-pruned-emaonly.ckpt%22%3B&Expires=1723114346&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMzExNDM0Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82Yi8yMC82YjIwMWRhNWYwZjVjNjA1MjQ1MzVlYmI3ZGVhYzJlZWY2ODYwNTY1NWQzYmJhY2ZlZTljY2UwMDg3ZjNiM2Y1L2NjNmNiMjcxMDM0MTczMjVmZjk0ZjUyYjdhNWQyZGRlNDVhNzUxNWIyNWMyNTVkOGUzOTZjOTAwMTQyODE1MTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=kKOwZt6%7EZTr8gBHBExVvyeDxt-mPhHeYA3-MhfsL0wc608Q0zJGfR3p--KeRUqfU0ZzPJSyAMBUWhyiGdoA4rYC0cUSOMJpUn0xUgw0GzM-JTewLgcE8NS-UMrPxCPJ3941ZEh849jaF--CLC4yHHW%7E-EGCz53nCflPu9U8Qx1pjfRgibQ7SA2BN24o62h%7EDpncBqsUr1%7EOlqsd56qjh79O7GRIGzUud4QkNQeUKDfiGQsHZad2KAV5-Atr4Q2iPUXwkLu2xwEauNoFhR5-VKlSCSQoDovi6UHb64VWiivZVZJkmLEMaJPz9fh6H8afyH3Xejy2wpiAY%7Ez%7E%7E0-FKvQ__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.161.180.53, 18.161.180.15, 18.161.180.68, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.161.180.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2024-08-05 11:04:09--  https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.67.181.126, 18.67.181.100, 18.67.181.36, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.67.181.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/ec/ee/eceee26c5834d8a75cf04eeb17dfc06d1d5fe1d80c2f19520b148c11e2e98c45/735e4c3a447a3255760d7f86845f09f937809baa529c17370d83e4c3758f3c75?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27vae-ft-mse-840000-ema-pruned.safetensors%3B+filename%3D%22vae-ft-mse-840000-ema-pruned.safetensors%22%3B&Expires=1723115049&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMzExNTA0OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy9lZS9lY2VlZTI2YzU4MzRkOGE3NWNmMDRlZWIxN2RmYzA2ZDFkNWZlMWQ4MGMyZjE5NTIwYjE0OGMxMWUyZTk4YzQ1LzczNWU0YzNhNDQ3YTMyNTU3NjBkN2Y4Njg0NWYwOWY5Mzc4MDliYWE1MjljMTczNzBkODNlNGMzNzU4ZjNjNzU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=DKf9CC%7EwL%7EMcY9yLglPJwwBqV5bWP5fSrid8oNirAeUX1Kj51oBR8CgdIitarrH5giUGIKwt0qmURqQ9gxYPBLHlKLfTLkkNgRGeyrVpiKj0HhBCj1UfpzKYjH%7EE95NHge0PBYmxhphuR0CNML5ENowLFISFgTcofG4x9uCnQPfiBEmTDu11UWxiONphMH3hLG%7Ea3Dcvs4uayYVA%7En8inpoJuIG5DBbUM9-AlptFJvcQyPasXUKhi%7EUJTXOGTcuJooZTJc-jiUsCtVi6jmQLQfJPquuchIen-yzENb-O%7EQQVJBv9GiPmhs970UwzdD9v9Bet0d%7EwBWbc5oOV4G-7Eg__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-08-05 11:04:09--  https://cdn-lfs.huggingface.co/repos/ec/ee/eceee26c5834d8a75cf04eeb17dfc06d1d5fe1d80c2f19520b148c11e2e98c45/735e4c3a447a3255760d7f86845f09f937809baa529c17370d83e4c3758f3c75?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27vae-ft-mse-840000-ema-pruned.safetensors%3B+filename%3D%22vae-ft-mse-840000-ema-pruned.safetensors%22%3B&Expires=1723115049&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMzExNTA0OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy9lZS9lY2VlZTI2YzU4MzRkOGE3NWNmMDRlZWIxN2RmYzA2ZDFkNWZlMWQ4MGMyZjE5NTIwYjE0OGMxMWUyZTk4YzQ1LzczNWU0YzNhNDQ3YTMyNTU3NjBkN2Y4Njg0NWYwOWY5Mzc4MDliYWE1MjljMTczNzBkODNlNGMzNzU4ZjNjNzU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=DKf9CC%7EwL%7EMcY9yLglPJwwBqV5bWP5fSrid8oNirAeUX1Kj51oBR8CgdIitarrH5giUGIKwt0qmURqQ9gxYPBLHlKLfTLkkNgRGeyrVpiKj0HhBCj1UfpzKYjH%7EE95NHge0PBYmxhphuR0CNML5ENowLFISFgTcofG4x9uCnQPfiBEmTDu11UWxiONphMH3hLG%7Ea3Dcvs4uayYVA%7En8inpoJuIG5DBbUM9-AlptFJvcQyPasXUKhi%7EUJTXOGTcuJooZTJc-jiUsCtVi6jmQLQfJPquuchIen-yzENb-O%7EQQVJBv9GiPmhs970UwzdD9v9Bet0d%7EwBWbc5oOV4G-7Eg__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.161.180.53, 18.161.180.15, 18.161.180.68, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.161.180.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Checkpoints\n",
        "\n",
        "### SDXL\n",
        "### I recommend these workflow examples: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/\n",
        "\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SDXL ReVision\n",
        "#!wget -c https://huggingface.co/comfyanonymous/clip_vision_g/resolve/main/clip_vision_g.safetensors -P ./models/clip_vision/\n",
        "\n",
        "# SD1.5\n",
        "!wget -c https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -P ./models/checkpoints/\n",
        "\n",
        "# SD2\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Some SD1.5 anime style\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (anime style SD2.x 768-v)\n",
        "#!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# unCLIP models\n",
        "#!wget -c https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# VAE\n",
        "!wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "\n",
        "# Loras\n",
        "#!wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "#!wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors -P ./models/loras/ #SDXL offset noise lora\n",
        "\n",
        "\n",
        "# T2I-Adapter\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n",
        "\n",
        "# T2I Styles Model\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision model (needed for styles model)\n",
        "#!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "\n",
        "# ControlNet\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "# ControlNet SDXL\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors -P ./models/controlnet/\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "#!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "\n",
        "# GLIGEN\n",
        "#!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P ./models/gligen/\n",
        "\n",
        "\n",
        "# ESRGAN upscale model\n",
        "#!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title FLUX.1 Setup\n",
        "!pip install -U huggingface_hub requests\n",
        "\n",
        "import os\n",
        "from huggingface_hub import login, hf_hub_download\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get the Hugging Face login token from userdata\n",
        "HF_LOGIN = userdata.get('HF_LOGIN')\n",
        "\n",
        "if not HF_LOGIN:\n",
        "    raise ValueError(\"HF_LOGIN not found in userdata. Please set it up in Google Colab.\")\n",
        "\n",
        "# Login to Hugging Face\n",
        "login(HF_LOGIN)\n",
        "\n",
        "# Define the paths\n",
        "WORKSPACE = \"/content/drive/MyDrive/ComfyUI\" if 'USE_GOOGLE_DRIVE' in globals() and USE_GOOGLE_DRIVE else os.path.join(os.getcwd(), \"ComfyUI\")\n",
        "UNET_DIR = os.path.join(WORKSPACE, \"models\", \"unet\")\n",
        "CLIP_DIR = os.path.join(WORKSPACE, \"models\", \"clip\")\n",
        "VAE_DIR = os.path.join(WORKSPACE, \"models\", \"vae\")\n",
        "\n",
        "# Create directories if they don't exist\n",
        "for dir_path in [UNET_DIR, CLIP_DIR, VAE_DIR]:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "# Download FLUX.1 model\n",
        "try:\n",
        "    flux_path = hf_hub_download(repo_id=\"black-forest-labs/FLUX.1-dev\", filename=\"flux1-dev.sft\")\n",
        "    os.rename(flux_path, os.path.join(UNET_DIR, \"flux1-dev.sft\"))\n",
        "    print(f\"FLUX.1 model downloaded to: {os.path.join(UNET_DIR, 'flux1-dev.sft')}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading FLUX.1 model: {str(e)}\")\n",
        "    print(\"Please check your Hugging Face token and ensure you have access to the repository.\")\n",
        "\n",
        "# Download CLIP models\n",
        "clip_urls = [\n",
        "    \"https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors\",\n",
        "    \"https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors\",\n",
        "    \"https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors\"\n",
        "]\n",
        "\n",
        "for url in clip_urls:\n",
        "    filename = url.split(\"/\")[-1]\n",
        "    try:\n",
        "        clip_path = hf_hub_download(repo_id=\"comfyanonymous/flux_text_encoders\", filename=filename)\n",
        "        os.rename(clip_path, os.path.join(CLIP_DIR, filename))\n",
        "        print(f\"Downloaded {filename} to {CLIP_DIR}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {filename}: {str(e)}\")\n",
        "\n",
        "# Download VAE\n",
        "try:\n",
        "    vae_path = hf_hub_download(repo_id=\"black-forest-labs/FLUX.1-schnell\", filename=\"ae.sft\")\n",
        "    os.rename(vae_path, os.path.join(VAE_DIR, \"ae.sft\"))\n",
        "    print(f\"Downloaded ae.sft to {VAE_DIR}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading VAE: {str(e)}\")\n",
        "\n",
        "# Download Workflow image\n",
        "workflow_url = \"https://github.com/comfyanonymous/ComfyUI_examples/raw/master/flux/flux_dev_example.png\"\n",
        "try:\n",
        "    response = requests.get(workflow_url)\n",
        "    response.raise_for_status()\n",
        "    with open(os.path.join(WORKSPACE, \"flux_dev_example.png\"), \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "    print(f\"Downloaded flux_dev_example.png to {WORKSPACE}\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading workflow image: {str(e)}\")\n",
        "\n",
        "print(\"Setup completed. Please check the output for any errors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFwGmW2FGYj8",
        "outputId": "3ef0ac62-9d92-4b05-c3a0-cffd601c7f42"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n",
            "FLUX.1 model downloaded to: /content/drive/MyDrive/ComfyUI/models/unet/flux1-dev.sft\n",
            "Downloaded clip_l.safetensors to /content/drive/MyDrive/ComfyUI/models/clip\n",
            "Downloaded t5xxl_fp16.safetensors to /content/drive/MyDrive/ComfyUI/models/clip\n",
            "Downloaded t5xxl_fp8_e4m3fn.safetensors to /content/drive/MyDrive/ComfyUI/models/clip\n",
            "Downloaded ae.sft to /content/drive/MyDrive/ComfyUI/models/vae\n",
            "Downloaded flux_dev_example.png to /content/drive/MyDrive/ComfyUI\n",
            "Setup completed. Please check the output for any errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkkk"
      },
      "source": [
        "### ComfyUIの起動\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a291b31-4a2e-4ba0-c408-1c4eddbf06fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-05 11:38:17--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2024.6.1/cloudflared-linux-amd64.deb [following]\n",
            "--2024-08-05 11:38:18--  https://github.com/cloudflare/cloudflared/releases/download/2024.6.1/cloudflared-linux-amd64.deb\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/3e345268-c5d6-4324-8389-71790dcf95ac?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240805%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240805T113818Z&X-Amz-Expires=300&X-Amz-Signature=0332b29a7d3838a8b7c3f438ed551ee0e0dfdc357f235e41b07bc3a0ee98dfb8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-08-05 11:38:18--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/3e345268-c5d6-4324-8389-71790dcf95ac?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240805%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240805T113818Z&X-Amz-Expires=300&X-Amz-Signature=0332b29a7d3838a8b7c3f438ed551ee0e0dfdc357f235e41b07bc3a0ee98dfb8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18229818 (17M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared-linux-amd64.deb.4’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  17.38M  84.6MB/s    in 0.2s    \n",
            "\n",
            "2024-08-05 11:38:19 (84.6 MB/s) - ‘cloudflared-linux-amd64.deb.4’ saved [18229818/18229818]\n",
            "\n",
            "(Reading database ... 123602 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2024.6.1) over (2024.6.1) ...\n",
            "Setting up cloudflared (2024.6.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2024-08-05 11:38:25.562846\n",
            "** Platform: Linux\n",
            "** Python version: 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/drive/MyDrive/ComfyUI\n",
            "** Log path: /content/drive/MyDrive/ComfyUI/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   3.6 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "Total VRAM 22700 MB, total RAM 54233 MB\n",
            "pytorch version: 2.3.1+cu121\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 NVIDIA L4 : cudaMallocAsync\n",
            "Using pytorch cross attention\n",
            "[Prompt Server] web root: /content/drive/MyDrive/ComfyUI/web\n",
            "### Loading: ComfyUI-Manager (V2.48.5)\n",
            "### ComfyUI Revision: 2469 [a178e259] | Released on '2024-08-05'\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   1.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "\n",
            "ComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\n",
            "\n",
            "This is the URL to access ComfyUI: https://scroll-visitors-respondents-fine.trycloudflare.com                                |\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
            "got prompt\n",
            "model weight dtype torch.bfloat16, manual cast: None\n",
            "model_type FLUX\n",
            "clip missing: ['text_projection.weight']\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21211.95\n",
            "100% 20/20 [00:42<00:00,  2.14s/it]\n",
            "Using pytorch attention in VAE\n",
            "Using pytorch attention in VAE\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 204.22 seconds\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:47<00:00,  2.14s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 132.29 seconds\n",
            "got prompt\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:47<00:00,  2.14s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 144.15 seconds\n",
            "got prompt\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 142.09 seconds\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  0% 0/50 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  2% 1/50 [00:02<01:44,  2.14s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  4% 2/50 [00:04<01:42,  2.14s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  6% 3/50 [00:06<01:40,  2.14s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  8% 4/50 [00:08<01:38,  2.14s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 10% 5/50 [00:10<01:36,  2.14s/it]got prompt\n",
            "got prompt\n",
            "100% 50/50 [01:46<00:00,  2.14s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 130.34 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 130.19 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.49 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.37 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.28 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.29 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.40 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.29 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.18 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.04 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.07 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.06 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.14 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            " 42% 21/50 [00:45<01:02,  2.14s/it]got prompt\n",
            "100% 50/50 [01:46<00:00,  2.14s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.56 seconds\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 141.02 seconds\n",
            "got prompt\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 140.60 seconds\n",
            "got prompt\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 140.47 seconds\n",
            "got prompt\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 140.38 seconds\n",
            "got prompt\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 140.74 seconds\n",
            "got prompt\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            " 64% 32/50 [01:08<00:38,  2.14s/it]got prompt\n",
            "100% 50/50 [01:46<00:00,  2.14s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 140.89 seconds\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 140.08 seconds\n",
            "got prompt\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.14s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 140.38 seconds\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            " 60% 30/50 [01:04<00:42,  2.14s/it]got prompt\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.37 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.14s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.44 seconds\n",
            "got prompt\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            " 26% 13/50 [00:27<01:18,  2.13s/it]got prompt\n",
            "got prompt\n",
            " 30% 15/50 [00:31<01:14,  2.14s/it]got prompt\n",
            " 50% 25/50 [00:53<00:53,  2.15s/it]got prompt\n",
            " 52% 26/50 [00:55<00:51,  2.15s/it]got prompt\n",
            "got prompt\n",
            " 54% 27/50 [00:57<00:49,  2.15s/it]got prompt\n",
            "got prompt\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 140.41 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Requested to load FluxClipModel_\n",
            "Loading 1 new model\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 140.95 seconds\n",
            "Requested to load Flux\n",
            "Loading 1 new model\n",
            "loading in lowvram mode 21193.95\n",
            "100% 50/50 [01:46<00:00,  2.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Prompt executed in 129.68 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n",
            "Prompt executed in 0.00 seconds\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
